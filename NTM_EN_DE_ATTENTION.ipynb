{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NTM_EN_DE_ATTENTION.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyuZ4un7cTv9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "416fb8f2-0cb9-4346-f762-fada5f13f6be"
      },
      "source": [
        "import spacy\n",
        "!spacy download en\n",
        "!spacy download de\n",
        "!pip install torchtext==0.6.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (46.3.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Requirement already satisfied: de_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz#egg=de_core_news_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (46.3.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.18.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n",
            "Requirement already satisfied: torchtext==0.6.0 in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.5.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.18.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (0.1.91)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (0.16.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGviie8tclva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext.datasets import TranslationDataset, Multi30k\n",
        "from torchtext.data import Field, BucketIterator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "spacy_de = spacy.load('de')\n",
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm6d-tnAercS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "bbeba02c-dabf-4557-e6aa-b4d0474fc194"
      },
      "source": [
        "def tokenize_de(text):\n",
        "    \"\"\"\n",
        "    Tokenizes German text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "SRC = Field(tokenize = tokenize_de, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True, \n",
        "            include_lengths = True)\n",
        "\n",
        "TRG = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True)\n",
        "\n",
        "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'), \n",
        "                                                    fields = (SRC, TRG))\n",
        "\n",
        "SRC.build_vocab(train_data, min_freq = 2)\n",
        "TRG.build_vocab(train_data, min_freq = 2)\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "     batch_size = BATCH_SIZE,\n",
        "     sort_within_batch = True,\n",
        "     sort_key = lambda x : len(x.src),\n",
        "     device = device)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading training.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:01<00:00, 799kB/s] \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading validation.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 220kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading mmt_task1_test2016.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 220kB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfzGhi7afEz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
        "        \n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_len):\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "                \n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len)\n",
        "                \n",
        "        packed_outputs, hidden = self.rnn(packed_embedded)\n",
        "            \n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs) \n",
        "            \n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "        \n",
        "        return outputs, hidden\n",
        "\n",
        "class Attention(nn.Module):\n",
        "\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
        "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
        "        \n",
        "    def forward(self, hidden, encoder_outputs, mask):\n",
        "        \n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "  \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
        "\n",
        "        attention = self.v(energy).squeeze(2)\n",
        "        \n",
        "        attention = attention.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        return F.softmax(attention, dim = 1)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "        \n",
        "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, encoder_outputs, mask):\n",
        "       \n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        \n",
        "        a = self.attention(hidden, encoder_outputs, mask)\n",
        "        \n",
        "        a = a.unsqueeze(1)\n",
        "        \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        \n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "        \n",
        "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
        "            \n",
        "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
        "        \n",
        "        assert (output == hidden).all()\n",
        "        \n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "        \n",
        "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n",
        "        \n",
        "        return prediction, hidden.squeeze(0), a.squeeze(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o6qt0KEgKUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "\n",
        "        self.decoder = decoder\n",
        "\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "\n",
        "        self.device = device\n",
        "        \n",
        "    def create_mask(self, src):\n",
        "\n",
        "        mask = (src != self.src_pad_idx).permute(1, 0)\n",
        "\n",
        "        return mask\n",
        "        \n",
        "    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n",
        "       \n",
        "        batch_size = src.shape[1]\n",
        "\n",
        "        trg_len = trg.shape[0]\n",
        "\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        encoder_outputs, hidden = self.encoder(src, src_len)\n",
        "                \n",
        "        input = trg[0,:]\n",
        "        \n",
        "        mask = self.create_mask(src)\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs, mask)\n",
        "            \n",
        "            outputs[t] = output\n",
        "            \n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            input = trg[t] if teacher_force else top1\n",
        "            \n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPsfsRv0gmhg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d9daa9d-9aec-4b8f-bbdd-47196f246687"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "ENC_HID_DIM = 512\n",
        "DEC_HID_DIM = 512\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, device).to(device)\n",
        "\n",
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "            \n",
        "model.apply(init_weights)\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 20,518,917 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grfMOSuBg0rm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src, src_len = batch.src\n",
        "        trg = batch.trg\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, src_len, trg)\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src, src_len = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output = model(src, src_len, trg, 0) #turn off teacher forcing\n",
        "            \n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rUNwSYphdLj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "outputId": "46984e8a-c179-4268-c1f7-5eee2f88cef7"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut4-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "\n",
        "model.load_state_dict(torch.load('tut4-model.pt'))\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 1m 33s\n",
            "\tTrain Loss: 5.045 | Train PPL: 155.267\n",
            "\t Val. Loss: 4.786 |  Val. PPL: 119.841\n",
            "Epoch: 02 | Time: 1m 32s\n",
            "\tTrain Loss: 4.130 | Train PPL:  62.203\n",
            "\t Val. Loss: 4.197 |  Val. PPL:  66.508\n",
            "Epoch: 03 | Time: 1m 32s\n",
            "\tTrain Loss: 3.381 | Train PPL:  29.408\n",
            "\t Val. Loss: 3.593 |  Val. PPL:  36.357\n",
            "Epoch: 04 | Time: 1m 33s\n",
            "\tTrain Loss: 2.875 | Train PPL:  17.733\n",
            "\t Val. Loss: 3.382 |  Val. PPL:  29.441\n",
            "Epoch: 05 | Time: 1m 32s\n",
            "\tTrain Loss: 2.490 | Train PPL:  12.061\n",
            "\t Val. Loss: 3.256 |  Val. PPL:  25.944\n",
            "Epoch: 06 | Time: 1m 33s\n",
            "\tTrain Loss: 2.206 | Train PPL:   9.082\n",
            "\t Val. Loss: 3.280 |  Val. PPL:  26.588\n",
            "Epoch: 07 | Time: 1m 32s\n",
            "\tTrain Loss: 1.960 | Train PPL:   7.096\n",
            "\t Val. Loss: 3.167 |  Val. PPL:  23.746\n",
            "Epoch: 08 | Time: 1m 32s\n",
            "\tTrain Loss: 1.769 | Train PPL:   5.863\n",
            "\t Val. Loss: 3.257 |  Val. PPL:  25.961\n",
            "Epoch: 09 | Time: 1m 32s\n",
            "\tTrain Loss: 1.614 | Train PPL:   5.021\n",
            "\t Val. Loss: 3.273 |  Val. PPL:  26.400\n",
            "Epoch: 10 | Time: 1m 32s\n",
            "\tTrain Loss: 1.502 | Train PPL:   4.492\n",
            "\t Val. Loss: 3.259 |  Val. PPL:  26.017\n",
            "| Test Loss: 3.167 | Test PPL:  23.735 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDFLEhS2hnsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "\n",
        "    model.eval()\n",
        "        \n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('de')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "    \n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "\n",
        "    src_len = torch.LongTensor([len(src_indexes)]).to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, hidden = model.encoder(src_tensor, src_len)\n",
        "\n",
        "    mask = model.create_mask(src_tensor)\n",
        "        \n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\n",
        "    \n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "                \n",
        "        with torch.no_grad():\n",
        "            output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs, mask)\n",
        "\n",
        "        attentions[i] = attention\n",
        "            \n",
        "        pred_token = output.argmax(1).item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:], attentions[:len(trg_tokens)-1]\n",
        "\n",
        "def display_attention(sentence, translation, attention):\n",
        "    \n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(111)\n",
        "    \n",
        "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
        "    \n",
        "    cax = ax.matshow(attention, cmap='bone')\n",
        "   \n",
        "    ax.tick_params(labelsize=15)\n",
        "    ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n",
        "                       rotation=45)\n",
        "    ax.set_yticklabels(['']+translation)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZIV3fJbln5W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "outputId": "b7bd177a-83be-4957-d961-38ab9fe64d26"
      },
      "source": [
        "example_idx = 14\n",
        "\n",
        "src = vars(valid_data.examples[example_idx])['src']\n",
        "trg = vars(valid_data.examples[example_idx])['trg']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "\n",
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')\n",
        "\n",
        "display_attention(src, translation, attention)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['eine', 'frau', 'spielt', 'ein', 'lied', 'auf', 'ihrer', 'geige', '.']\n",
            "trg = ['a', 'female', 'playing', 'a', 'song', 'on', 'her', 'violin', '.']\n",
            "predicted trg = ['a', 'woman', 'is', 'playing', 'a', 'song', 'on', 'her', 'harp', '.', '<eos>']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fvkxqVolvIf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "160a0567-7b8e-4a04-da9d-824a3f1536d3"
      },
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "def calculate_bleu(data, src_field, trg_field, model, device, max_len = 50):\n",
        "    \n",
        "    trgs = []\n",
        "    pred_trgs = []\n",
        "    \n",
        "    for datum in data:\n",
        "        \n",
        "        src = vars(datum)['src']\n",
        "        trg = vars(datum)['trg']\n",
        "        \n",
        "        pred_trg, _ = translate_sentence(src, src_field, trg_field, model, device, max_len)\n",
        "        \n",
        "        #cut off <eos> token\n",
        "        pred_trg = pred_trg[:-1]\n",
        "        \n",
        "        pred_trgs.append(pred_trg)\n",
        "        trgs.append([trg])\n",
        "        \n",
        "    return bleu_score(pred_trgs, trgs)\n",
        "\n",
        "bleu_score = calculate_bleu(test_data, SRC, TRG, model, device)\n",
        "\n",
        "print(f'BLEU score = {bleu_score*100:.2f}')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU score = 28.84\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJO-T_tFl1e3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}